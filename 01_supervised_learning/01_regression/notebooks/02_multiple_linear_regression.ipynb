{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4cd8640",
   "metadata": {},
   "source": [
    "# üìä Multiple Linear Regression - Complete Beginner's Guide\n",
    "\n",
    "Welcome to the next level of machine learning! After mastering simple linear regression, you're ready to handle **multiple features** simultaneously.\n",
    "\n",
    "## üéØ What You'll Learn\n",
    "\n",
    "By the end of this notebook, you'll understand:\n",
    "- **What is Multiple Linear Regression?** (Using multiple factors to predict)\n",
    "- **How it differs from Simple Linear Regression** (One vs many features)\n",
    "- **Categorical encoding** (Converting text to numbers)\n",
    "- **Feature importance** (Which factors matter most)\n",
    "- **Real-world business applications** (Startup profit prediction)\n",
    "\n",
    "## üß† The Big Picture\n",
    "\n",
    "**The Problem:** Can we predict a startup's profit using multiple business factors?\n",
    "\n",
    "**The Approach:** Instead of just one feature (like experience), we'll use multiple features:\n",
    "- R&D Spending üí°\n",
    "- Administration Costs üíº  \n",
    "- Marketing Spend üì±\n",
    "- Location (State) üìç\n",
    "\n",
    "**Real-World Application:** Investors use this to evaluate startup potential, entrepreneurs to optimize spending, and VCs to make funding decisions.\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Simple vs Multiple Linear Regression\n",
    "\n",
    "### **Simple Linear Regression:**\n",
    "```\n",
    "Profit = (Slope √ó R&D_Spending) + Intercept\n",
    "One line, one relationship\n",
    "```\n",
    "\n",
    "### **Multiple Linear Regression:**\n",
    "```\n",
    "Profit = (Coef1 √ó R&D) + (Coef2 √ó Admin) + (Coef3 √ó Marketing) + (Coef4 √ó State_Feature) + Intercept\n",
    "Multiple relationships combined!\n",
    "```\n",
    "\n",
    "**Key Insight:** We're finding the best \"hyperplane\" (multi-dimensional surface) instead of just a line!\n",
    "\n",
    "---\n",
    "\n",
    "## üõ†Ô∏è Step-by-Step Process\n",
    "\n",
    "1. **üìä Import Libraries & Load Data**\n",
    "2. **üîç Explore the Startup Dataset** \n",
    "3. **üßπ Clean the Data**\n",
    "4. **üè∑Ô∏è Encode Categorical Variables** (Convert \"State\" to numbers)\n",
    "5. **‚úÇÔ∏è Split Training & Test Sets**\n",
    "6. **üéì Train the Multiple Linear Regression Model**\n",
    "7. **üìè Evaluate Performance**\n",
    "8. **üîÆ Make Predictions**\n",
    "9. **üìà Analyze Feature Importance**\n",
    "10. **üí° Business Insights & Applications**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6fb48e",
   "metadata": {},
   "source": [
    "## üìä Step 1: Import Libraries\n",
    "\n",
    "**Why these specific libraries for Multiple Linear Regression?**\n",
    "- **pandas**: Handle tabular data with multiple columns\n",
    "- **numpy**: Mathematical operations on multi-dimensional arrays\n",
    "- **matplotlib**: Visualize relationships between multiple variables\n",
    "- **seaborn**: Advanced statistical plots for multiple features\n",
    "- **scikit-learn**: Machine learning algorithms and preprocessing tools\n",
    "\n",
    "**New for Multiple Regression:**\n",
    "- **ColumnTransformer**: Handle different preprocessing for different columns\n",
    "- **OneHotEncoder**: Convert categorical variables to numerical format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f76539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential libraries for Multiple Linear Regression\n",
    "import pandas as pd              # Data manipulation and analysis\n",
    "import numpy as np              # Mathematical operations\n",
    "import matplotlib.pyplot as plt # Basic plotting\n",
    "import seaborn as sns           # Statistical visualizations\n",
    "\n",
    "# Set style for better-looking plots\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")\n",
    "print(\"üöÄ Ready for Multiple Linear Regression analysis!\")\n",
    "print(\"\\nüí° Key libraries for this project:\")\n",
    "print(\"   üìä pandas: Handle startup dataset with multiple features\")\n",
    "print(\"   üî¢ numpy: Mathematical operations on feature matrices\")\n",
    "print(\"   üìà matplotlib/seaborn: Visualize multi-feature relationships\")\n",
    "print(\"   ü§ñ scikit-learn: ML algorithms and preprocessing (imported later)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73fe929",
   "metadata": {},
   "source": [
    "## üìÇ Step 2: Load and Explore the Startup Dataset\n",
    "\n",
    "**About the Dataset:**\n",
    "This dataset contains information about 50 startups, including:\n",
    "- **R&D Spend**: Money invested in Research & Development üí°\n",
    "- **Administration**: Administrative/operational costs üíº\n",
    "- **Marketing Spend**: Money spent on marketing campaigns üì±\n",
    "- **State**: Location of the startup (New York, California, Florida) üìç\n",
    "- **Profit**: Company profit (our target variable) üí∞\n",
    "\n",
    "**Why this dataset is perfect for Multiple Linear Regression:**\n",
    "- **Multiple numerical features**: R&D, Admin, Marketing spending\n",
    "- **One categorical feature**: State (needs encoding)\n",
    "- **Clear business logic**: More investment should lead to higher profits\n",
    "- **Real-world relevance**: Actual business decision-making scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef40a67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the 50 Startups dataset\n",
    "dataset = pd.read_csv('../data/50_Startups.csv')\n",
    "\n",
    "print(\"üìã DATASET OVERVIEW\")\n",
    "print(\"=\"*25)\n",
    "print(f\"Shape: {dataset.shape} (rows, columns)\")\n",
    "print(f\"Features: {dataset.shape[1]-1} | Target: 1 (Profit)\")\n",
    "\n",
    "print(\"\\nüìä First 5 rows:\")\n",
    "display(dataset.head())\n",
    "\n",
    "print(\"\\nüìà Dataset Info:\")\n",
    "print(dataset.info())\n",
    "\n",
    "print(\"\\nüìä Basic Statistics:\")\n",
    "display(dataset.describe())\n",
    "\n",
    "print(\"\\nüè∑Ô∏è Column Details:\")\n",
    "for i, col in enumerate(dataset.columns):\n",
    "    dtype = dataset[col].dtype\n",
    "    if col == 'Profit':\n",
    "        print(f\"   üéØ {col}: {dtype} (Target Variable - what we predict)\")\n",
    "    elif col == 'State':\n",
    "        print(f\"   üìç {col}: {dtype} (Categorical - needs encoding)\")\n",
    "    else:\n",
    "        print(f\"   üí∞ {col}: {dtype} (Numerical Feature)\")\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X = dataset.iloc[:, :-1]  # All columns except the last (features)\n",
    "y = dataset.iloc[:, -1]   # Last column only (target)\n",
    "\n",
    "print(f\"\\n‚úÖ Data loaded successfully!\")\n",
    "print(f\"üìä Features (X): {X.shape} - R&D, Administration, Marketing, State\")\n",
    "print(f\"üéØ Target (y): {y.shape} - Profit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e977d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    R&D Spend  Administration  Marketing Spend       State     Profit\n",
      "0   165349.20       136897.80        471784.10    New York  192261.83\n",
      "1   162597.70       151377.59        443898.53  California  191792.06\n",
      "2   153441.51       101145.55        407934.54     Florida  191050.39\n",
      "3   144372.41       118671.85        383199.62    New York  182901.99\n",
      "4   142107.34        91391.77        366168.42     Florida  166187.94\n",
      "5   131876.90        99814.71        362861.36    New York  156991.12\n",
      "6   134615.46       147198.87        127716.82  California  156122.51\n",
      "7   130298.13       145530.06        323876.68     Florida  155752.60\n",
      "8   120542.52       148718.95        311613.29    New York  152211.77\n",
      "9   123334.88       108679.17        304981.62  California  149759.96\n",
      "10  101913.08       110594.11        229160.95     Florida  146121.95\n",
      "11  100671.96        91790.61        249744.55  California  144259.40\n",
      "12   93863.75       127320.38        249839.44     Florida  141585.52\n",
      "13   91992.39       135495.07        252664.93  California  134307.35\n",
      "14  119943.24       156547.42        256512.92     Florida  132602.65\n",
      "15  114523.61       122616.84        261776.23    New York  129917.04\n",
      "16   78013.11       121597.55        264346.06  California  126992.93\n",
      "17   94657.16       145077.58        282574.31    New York  125370.37\n",
      "18   91749.16       114175.79        294919.57     Florida  124266.90\n",
      "19   86419.70       153514.11             0.00    New York  122776.86\n",
      "20   76253.86       113867.30        298664.47  California  118474.03\n",
      "21   78389.47       153773.43        299737.29    New York  111313.02\n",
      "22   73994.56       122782.75        303319.26     Florida  110352.25\n",
      "23   67532.53       105751.03        304768.73     Florida  108733.99\n",
      "24   77044.01        99281.34        140574.81    New York  108552.04\n",
      "25   64664.71       139553.16        137962.62  California  107404.34\n",
      "26   75328.87       144135.98        134050.07     Florida  105733.54\n",
      "27   72107.60       127864.55        353183.81    New York  105008.31\n",
      "28   66051.52       182645.56        118148.20     Florida  103282.38\n",
      "29   65605.48       153032.06        107138.38    New York  101004.64\n",
      "30   61994.48       115641.28         91131.24     Florida   99937.59\n",
      "31   61136.38       152701.92         88218.23    New York   97483.56\n",
      "32   63408.86       129219.61         46085.25  California   97427.84\n",
      "33   55493.95       103057.49        214634.81     Florida   96778.92\n",
      "34   46426.07       157693.92        210797.67  California   96712.80\n",
      "35   46014.02        85047.44        205517.64    New York   96479.51\n",
      "36   28663.76       127056.21        201126.82     Florida   90708.19\n",
      "37   44069.95        51283.14        197029.42  California   89949.14\n",
      "38   20229.59        65947.93        185265.10    New York   81229.06\n",
      "39   38558.51        82982.09        174999.30  California   81005.76\n",
      "40   28754.33       118546.05        172795.67  California   78239.91\n",
      "41   27892.92        84710.77        164470.71     Florida   77798.83\n",
      "42   23640.93        96189.63        148001.11  California   71498.49\n",
      "43   15505.73       127382.30         35534.17    New York   69758.98\n",
      "44   22177.74       154806.14         28334.72  California   65200.33\n",
      "45    1000.23       124153.04          1903.93    New York   64926.08\n",
      "46    1315.46       115816.21        297114.46     Florida   49490.75\n",
      "47       0.00       135426.92             0.00  California   42559.73\n",
      "48     542.05        51743.15             0.00    New York   35673.41\n",
      "49       0.00       116983.80         45173.06  California   14681.40\n"
     ]
    }
   ],
   "source": [
    "# üîç Comprehensive Exploratory Data Analysis\n",
    "print(\"üîç DETAILED DATASET EXPLORATION\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "print(\"üìã Complete Dataset:\")\n",
    "display(dataset)\n",
    "\n",
    "print(f\"\\nüìä Dataset Composition:\")\n",
    "print(f\"   üë• Number of startups: {len(dataset)}\")\n",
    "print(f\"   üìç States represented: {dataset['State'].nunique()}\")\n",
    "print(f\"   üè∑Ô∏è State distribution:\")\n",
    "for state, count in dataset['State'].value_counts().items():\n",
    "    print(f\"      {state}: {count} startups ({count/len(dataset)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nüí∞ Financial Overview:\")\n",
    "print(f\"   üí° R&D Spend: ${dataset['R&D Spend'].min():,.0f} - ${dataset['R&D Spend'].max():,.0f}\")\n",
    "print(f\"   üíº Administration: ${dataset['Administration'].min():,.0f} - ${dataset['Administration'].max():,.0f}\")\n",
    "print(f\"   üì± Marketing Spend: ${dataset['Marketing Spend'].min():,.0f} - ${dataset['Marketing Spend'].max():,.0f}\")\n",
    "print(f\"   üéØ Profit Range: ${dataset['Profit'].min():,.0f} - ${dataset['Profit'].max():,.0f}\")\n",
    "\n",
    "# Check for any missing values\n",
    "print(f\"\\n‚ùì Missing Values Check:\")\n",
    "missing_summary = dataset.isnull().sum()\n",
    "for column, missing_count in missing_summary.items():\n",
    "    if missing_count > 0:\n",
    "        print(f\"   ‚ö†Ô∏è {column}: {missing_count} missing ({missing_count/len(dataset)*100:.1f}%)\")\n",
    "    else:\n",
    "        print(f\"   ‚úÖ {column}: No missing values\")\n",
    "\n",
    "print(f\"\\nüéâ Dataset is ready for analysis!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9660fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    R&D Spend  Administration  Marketing Spend       State\n",
      "0   165349.20       136897.80        471784.10    New York\n",
      "1   162597.70       151377.59        443898.53  California\n",
      "2   153441.51       101145.55        407934.54     Florida\n",
      "3   144372.41       118671.85        383199.62    New York\n",
      "4   142107.34        91391.77        366168.42     Florida\n",
      "5   131876.90        99814.71        362861.36    New York\n",
      "6   134615.46       147198.87        127716.82  California\n",
      "7   130298.13       145530.06        323876.68     Florida\n",
      "8   120542.52       148718.95        311613.29    New York\n",
      "9   123334.88       108679.17        304981.62  California\n",
      "10  101913.08       110594.11        229160.95     Florida\n",
      "11  100671.96        91790.61        249744.55  California\n",
      "12   93863.75       127320.38        249839.44     Florida\n",
      "13   91992.39       135495.07        252664.93  California\n",
      "14  119943.24       156547.42        256512.92     Florida\n",
      "15  114523.61       122616.84        261776.23    New York\n",
      "16   78013.11       121597.55        264346.06  California\n",
      "17   94657.16       145077.58        282574.31    New York\n",
      "18   91749.16       114175.79        294919.57     Florida\n",
      "19   86419.70       153514.11             0.00    New York\n",
      "20   76253.86       113867.30        298664.47  California\n",
      "21   78389.47       153773.43        299737.29    New York\n",
      "22   73994.56       122782.75        303319.26     Florida\n",
      "23   67532.53       105751.03        304768.73     Florida\n",
      "24   77044.01        99281.34        140574.81    New York\n",
      "25   64664.71       139553.16        137962.62  California\n",
      "26   75328.87       144135.98        134050.07     Florida\n",
      "27   72107.60       127864.55        353183.81    New York\n",
      "28   66051.52       182645.56        118148.20     Florida\n",
      "29   65605.48       153032.06        107138.38    New York\n",
      "30   61994.48       115641.28         91131.24     Florida\n",
      "31   61136.38       152701.92         88218.23    New York\n",
      "32   63408.86       129219.61         46085.25  California\n",
      "33   55493.95       103057.49        214634.81     Florida\n",
      "34   46426.07       157693.92        210797.67  California\n",
      "35   46014.02        85047.44        205517.64    New York\n",
      "36   28663.76       127056.21        201126.82     Florida\n",
      "37   44069.95        51283.14        197029.42  California\n",
      "38   20229.59        65947.93        185265.10    New York\n",
      "39   38558.51        82982.09        174999.30  California\n",
      "40   28754.33       118546.05        172795.67  California\n",
      "41   27892.92        84710.77        164470.71     Florida\n",
      "42   23640.93        96189.63        148001.11  California\n",
      "43   15505.73       127382.30         35534.17    New York\n",
      "44   22177.74       154806.14         28334.72  California\n",
      "45    1000.23       124153.04          1903.93    New York\n",
      "46    1315.46       115816.21        297114.46     Florida\n",
      "47       0.00       135426.92             0.00  California\n",
      "48     542.05        51743.15             0.00    New York\n",
      "49       0.00       116983.80         45173.06  California\n"
     ]
    }
   ],
   "source": [
    "# üìä Features (X) - What we use to predict profit\n",
    "print(\"üìä FEATURES (Independent Variables)\")\n",
    "print(\"=\"*40)\n",
    "print(\"Shape:\", X.shape)\n",
    "print(\"Columns:\", list(X.columns))\n",
    "\n",
    "print(\"\\nüîç Features Sample:\")\n",
    "display(X.head(10))\n",
    "\n",
    "print(\"\\nüí° Feature Types:\")\n",
    "for col in X.columns:\n",
    "    if X[col].dtype == 'object':\n",
    "        print(f\"   üìù {col}: Categorical (needs encoding)\")\n",
    "        print(f\"      Unique values: {X[col].unique()}\")\n",
    "    else:\n",
    "        print(f\"   üî¢ {col}: Numerical (ready for modeling)\")\n",
    "        print(f\"      Range: ${X[col].min():,.0f} - ${X[col].max():,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382144d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     192261.83\n",
      "1     191792.06\n",
      "2     191050.39\n",
      "3     182901.99\n",
      "4     166187.94\n",
      "5     156991.12\n",
      "6     156122.51\n",
      "7     155752.60\n",
      "8     152211.77\n",
      "9     149759.96\n",
      "10    146121.95\n",
      "11    144259.40\n",
      "12    141585.52\n",
      "13    134307.35\n",
      "14    132602.65\n",
      "15    129917.04\n",
      "16    126992.93\n",
      "17    125370.37\n",
      "18    124266.90\n",
      "19    122776.86\n",
      "20    118474.03\n",
      "21    111313.02\n",
      "22    110352.25\n",
      "23    108733.99\n",
      "24    108552.04\n",
      "25    107404.34\n",
      "26    105733.54\n",
      "27    105008.31\n",
      "28    103282.38\n",
      "29    101004.64\n",
      "30     99937.59\n",
      "31     97483.56\n",
      "32     97427.84\n",
      "33     96778.92\n",
      "34     96712.80\n",
      "35     96479.51\n",
      "36     90708.19\n",
      "37     89949.14\n",
      "38     81229.06\n",
      "39     81005.76\n",
      "40     78239.91\n",
      "41     77798.83\n",
      "42     71498.49\n",
      "43     69758.98\n",
      "44     65200.33\n",
      "45     64926.08\n",
      "46     49490.75\n",
      "47     42559.73\n",
      "48     35673.41\n",
      "49     14681.40\n",
      "Name: Profit, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# üéØ Target Variable (y) - What we want to predict\n",
    "print(\"üéØ TARGET VARIABLE (Dependent Variable)\")\n",
    "print(\"=\"*45)\n",
    "print(\"Shape:\", y.shape)\n",
    "print(\"Name: Profit\")\n",
    "\n",
    "print(\"\\nüí∞ Profit Analysis:\")\n",
    "print(f\"   üìä Mean Profit: ${y.mean():,.2f}\")\n",
    "print(f\"   üìä Median Profit: ${y.median():,.2f}\")\n",
    "print(f\"   üìä Min Profit: ${y.min():,.2f}\")\n",
    "print(f\"   üìä Max Profit: ${y.max():,.2f}\")\n",
    "print(f\"   üìä Standard Deviation: ${y.std():,.2f}\")\n",
    "\n",
    "print(f\"\\nüìà Profit Distribution:\")\n",
    "print(\"First 10 values:\")\n",
    "for i, profit in enumerate(y.head(10)):\n",
    "    print(f\"   Startup {i+1}: ${profit:,.2f}\")\n",
    "\n",
    "print(f\"\\nüí° Key Insights:\")\n",
    "profit_range = y.max() - y.min()\n",
    "print(f\"   üìä Profit varies by ${profit_range:,.2f} across startups\")\n",
    "print(f\"   üéØ Our model will try to predict these profit values\")\n",
    "print(f\"   üìà Success metric: How close our predictions are to actual profits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e30e077",
   "metadata": {},
   "source": [
    "## üßπ Step 3: Data Quality Check\n",
    "\n",
    "**Why check for missing data in Multiple Linear Regression?**\n",
    "- **More features = more chances for missing values**\n",
    "- **Missing data can break the model** or lead to biased results\n",
    "- **Different strategies** for different types of missing data\n",
    "\n",
    "**Multiple Linear Regression is sensitive to:**\n",
    "- **Complete cases**: Most algorithms need all features present\n",
    "- **Feature relationships**: Missing data can distort correlations\n",
    "- **Sample size**: Removing too many rows reduces training data\n",
    "\n",
    "**Common handling strategies:**\n",
    "1. **Remove rows** with missing values (if few)\n",
    "2. **Impute with mean/median** for numerical features\n",
    "3. **Impute with mode** for categorical features  \n",
    "4. **Advanced imputation** using other features to predict missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9472c72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "R&D Spend          0\n",
       "Administration     0\n",
       "Marketing Spend    0\n",
       "State              0\n",
       "Profit             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# üßπ Comprehensive Data Quality Assessment\n",
    "print(\"üßπ DATA QUALITY CHECK\")\n",
    "print(\"=\"*25)\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = dataset.isnull().sum()\n",
    "total_cells = len(dataset) * len(dataset.columns)\n",
    "total_missing = missing_values.sum()\n",
    "\n",
    "print(\"‚ùì Missing Values Analysis:\")\n",
    "print(f\"   üìä Total cells in dataset: {total_cells:,}\")\n",
    "print(f\"   üìä Total missing values: {total_missing}\")\n",
    "print(f\"   üìä Missing percentage: {(total_missing/total_cells)*100:.2f}%\")\n",
    "\n",
    "print(f\"\\nüìã Per-column missing values:\")\n",
    "for column, missing_count in missing_values.items():\n",
    "    if missing_count > 0:\n",
    "        percentage = (missing_count / len(dataset)) * 100\n",
    "        print(f\"   ‚ö†Ô∏è {column}: {missing_count} missing ({percentage:.1f}%)\")\n",
    "    else:\n",
    "        print(f\"   ‚úÖ {column}: No missing values\")\n",
    "\n",
    "# Check for duplicates\n",
    "duplicates = dataset.duplicated().sum()\n",
    "print(f\"\\nüìã Duplicate Rows: {duplicates}\")\n",
    "\n",
    "# Data type verification\n",
    "print(f\"\\nüî¢ Data Types Check:\")\n",
    "for column, dtype in dataset.dtypes.items():\n",
    "    if column == 'State':\n",
    "        print(f\"   üìù {column}: {dtype} ‚úÖ (Categorical - expected)\")\n",
    "    elif dtype in ['int64', 'float64']:\n",
    "        print(f\"   üî¢ {column}: {dtype} ‚úÖ (Numerical - ready)\")\n",
    "    else:\n",
    "        print(f\"   ‚ö†Ô∏è {column}: {dtype} (May need attention)\")\n",
    "\n",
    "# Summary\n",
    "print(f\"\\n‚úÖ DATA QUALITY SUMMARY:\")\n",
    "if total_missing == 0:\n",
    "    print(f\"   üéâ Perfect! No missing values found\")\n",
    "else:\n",
    "    print(f\"   ‚ö†Ô∏è Found {total_missing} missing values - need handling strategy\")\n",
    "\n",
    "if duplicates == 0:\n",
    "    print(f\"   ‚úÖ No duplicate rows\")\n",
    "else:\n",
    "    print(f\"   ‚ö†Ô∏è Found {duplicates} duplicate rows - consider removing\")\n",
    "\n",
    "print(f\"   üìä Dataset size: {len(dataset)} startups with {len(dataset.columns)} features\")\n",
    "print(f\"   üéØ Ready for feature encoding and modeling!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cab0fd9",
   "metadata": {},
   "source": [
    "## üè∑Ô∏è Step 4: Encode Categorical Variables\n",
    "\n",
    "**The Problem:** Computers can't directly work with text like \"California\", \"New York\", \"Florida\"\n",
    "\n",
    "**The Solution:** Convert categorical variables to numerical format using **One-Hot Encoding**\n",
    "\n",
    "### **What is One-Hot Encoding?**\n",
    "\n",
    "**Before encoding (State column):**\n",
    "```\n",
    "California\n",
    "New York  \n",
    "Florida\n",
    "```\n",
    "\n",
    "**After one-hot encoding (3 new columns):**\n",
    "```\n",
    "California  New York  Florida\n",
    "    1          0        0\n",
    "    0          1        0  \n",
    "    0          0        1\n",
    "```\n",
    "\n",
    "**Why One-Hot Encoding?**\n",
    "- ‚úÖ **No ordinality assumed**: California isn't \"greater\" than New York\n",
    "- ‚úÖ **Equal treatment**: Each state gets equal importance\n",
    "- ‚úÖ **Algorithm compatibility**: All inputs are now numbers\n",
    "\n",
    "**Alternative approaches:**\n",
    "- **Label Encoding**: California=0, New York=1, Florida=2 (‚ùå implies order)\n",
    "- **Target Encoding**: Use average profit per state (‚ö†Ô∏è can cause data leakage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb10784e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üè∑Ô∏è Encoding Categorical Variables using One-Hot Encoding\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "print(\"üè∑Ô∏è CATEGORICAL VARIABLE ENCODING\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# Show the original categorical data\n",
    "print(\"üìù Original State column (categorical):\")\n",
    "print(f\"   Unique states: {X['State'].unique()}\")\n",
    "print(f\"   State distribution:\")\n",
    "for state, count in X['State'].value_counts().items():\n",
    "    print(f\"      {state}: {count} startups\")\n",
    "\n",
    "print(f\"\\nüîß Applying One-Hot Encoding...\")\n",
    "\n",
    "# Set up the ColumnTransformer for one-hot encoding\n",
    "# We want to encode column index 3 (State column) and keep other columns as-is\n",
    "ct = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('encoder', OneHotEncoder(), [3])  # Apply OneHotEncoder to column 3 (State)\n",
    "    ],\n",
    "    remainder='passthrough'  # Keep other columns unchanged\n",
    ")\n",
    "\n",
    "# Apply the transformation\n",
    "X_encoded = np.array(ct.fit_transform(X))\n",
    "\n",
    "print(\"‚úÖ Encoding complete!\")\n",
    "\n",
    "# Show the results\n",
    "print(f\"\\nüìä ENCODING RESULTS:\")\n",
    "print(f\"   üìè Original shape: {X.shape}\")\n",
    "print(f\"   üìè New shape: {X_encoded.shape}\")\n",
    "print(f\"   üìà Added {X_encoded.shape[1] - X.shape[1]} new columns\")\n",
    "\n",
    "print(f\"\\nüîç New column structure:\")\n",
    "feature_names = ct.get_feature_names_out()\n",
    "for i, name in enumerate(feature_names):\n",
    "    print(f\"   Column {i}: {name}\")\n",
    "\n",
    "print(f\"\\nüìã Sample of encoded data (first 5 rows):\")\n",
    "print(\"   [First 3 cols = One-hot encoded states, Last 3 cols = Original numerical features]\")\n",
    "for i in range(5):\n",
    "    row_data = [f\"{val:.1f}\" if isinstance(val, (int, float)) and val > 100 else f\"{val:.0f}\" for val in X_encoded[i]]\n",
    "    print(f\"   Row {i+1}: [{', '.join(row_data)}]\")\n",
    "\n",
    "# Update X to use encoded version  \n",
    "X = X_encoded\n",
    "\n",
    "print(f\"\\nüí° INTERPRETATION:\")\n",
    "print(f\"   üè∑Ô∏è State information now represented as 3 binary columns\")\n",
    "print(f\"   üî¢ All features are now numerical and ready for modeling\")\n",
    "print(f\"   üìä Each row has {X.shape[1]} features instead of {X.shape[1]-1}\")\n",
    "print(f\"   ‚úÖ No information lost - just converted to machine-readable format!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200af84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0000000e+00 0.0000000e+00 1.0000000e+00 1.6534920e+05 1.3689780e+05\n",
      "  4.7178410e+05]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 1.6259770e+05 1.5137759e+05\n",
      "  4.4389853e+05]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.5344151e+05 1.0114555e+05\n",
      "  4.0793454e+05]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00 1.4437241e+05 1.1867185e+05\n",
      "  3.8319962e+05]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.4210734e+05 9.1391770e+04\n",
      "  3.6616842e+05]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00 1.3187690e+05 9.9814710e+04\n",
      "  3.6286136e+05]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 1.3461546e+05 1.4719887e+05\n",
      "  1.2771682e+05]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.3029813e+05 1.4553006e+05\n",
      "  3.2387668e+05]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00 1.2054252e+05 1.4871895e+05\n",
      "  3.1161329e+05]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 1.2333488e+05 1.0867917e+05\n",
      "  3.0498162e+05]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.0191308e+05 1.1059411e+05\n",
      "  2.2916095e+05]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 1.0067196e+05 9.1790610e+04\n",
      "  2.4974455e+05]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00 9.3863750e+04 1.2732038e+05\n",
      "  2.4983944e+05]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 9.1992390e+04 1.3549507e+05\n",
      "  2.5266493e+05]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.1994324e+05 1.5654742e+05\n",
      "  2.5651292e+05]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00 1.1452361e+05 1.2261684e+05\n",
      "  2.6177623e+05]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 7.8013110e+04 1.2159755e+05\n",
      "  2.6434606e+05]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00 9.4657160e+04 1.4507758e+05\n",
      "  2.8257431e+05]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00 9.1749160e+04 1.1417579e+05\n",
      "  2.9491957e+05]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00 8.6419700e+04 1.5351411e+05\n",
      "  0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 7.6253860e+04 1.1386730e+05\n",
      "  2.9866447e+05]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00 7.8389470e+04 1.5377343e+05\n",
      "  2.9973729e+05]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00 7.3994560e+04 1.2278275e+05\n",
      "  3.0331926e+05]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00 6.7532530e+04 1.0575103e+05\n",
      "  3.0476873e+05]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00 7.7044010e+04 9.9281340e+04\n",
      "  1.4057481e+05]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 6.4664710e+04 1.3955316e+05\n",
      "  1.3796262e+05]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00 7.5328870e+04 1.4413598e+05\n",
      "  1.3405007e+05]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00 7.2107600e+04 1.2786455e+05\n",
      "  3.5318381e+05]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00 6.6051520e+04 1.8264556e+05\n",
      "  1.1814820e+05]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00 6.5605480e+04 1.5303206e+05\n",
      "  1.0713838e+05]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00 6.1994480e+04 1.1564128e+05\n",
      "  9.1131240e+04]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00 6.1136380e+04 1.5270192e+05\n",
      "  8.8218230e+04]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 6.3408860e+04 1.2921961e+05\n",
      "  4.6085250e+04]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00 5.5493950e+04 1.0305749e+05\n",
      "  2.1463481e+05]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 4.6426070e+04 1.5769392e+05\n",
      "  2.1079767e+05]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00 4.6014020e+04 8.5047440e+04\n",
      "  2.0551764e+05]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.8663760e+04 1.2705621e+05\n",
      "  2.0112682e+05]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 4.4069950e+04 5.1283140e+04\n",
      "  1.9702942e+05]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00 2.0229590e+04 6.5947930e+04\n",
      "  1.8526510e+05]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 3.8558510e+04 8.2982090e+04\n",
      "  1.7499930e+05]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 2.8754330e+04 1.1854605e+05\n",
      "  1.7279567e+05]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.7892920e+04 8.4710770e+04\n",
      "  1.6447071e+05]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 2.3640930e+04 9.6189630e+04\n",
      "  1.4800111e+05]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00 1.5505730e+04 1.2738230e+05\n",
      "  3.5534170e+04]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 2.2177740e+04 1.5480614e+05\n",
      "  2.8334720e+04]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00 1.0002300e+03 1.2415304e+05\n",
      "  1.9039300e+03]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.3154600e+03 1.1581621e+05\n",
      "  2.9711446e+05]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.3542692e+05\n",
      "  0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00 5.4205000e+02 5.1743150e+04\n",
      "  0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.1698380e+05\n",
      "  4.5173060e+04]]\n"
     ]
    }
   ],
   "source": [
    "# üìä Detailed view of encoded features\n",
    "print(\"üìä ENCODED FEATURES DETAILED VIEW\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "print(f\"üîç Complete encoded dataset shape: {X.shape}\")\n",
    "print(f\"üìè Features per startup: {X.shape[1]}\")\n",
    "\n",
    "print(f\"\\nüìã All encoded data:\")\n",
    "print(\"   Format: [State_Encoded(3 cols) | R&D_Spend | Administration | Marketing_Spend]\")\n",
    "\n",
    "# Create a more readable display\n",
    "encoded_df = pd.DataFrame(X, columns=[\n",
    "    'State_0', 'State_1', 'State_2', \n",
    "    'R&D_Spend', 'Administration', 'Marketing_Spend'\n",
    "])\n",
    "\n",
    "# Add original state names for reference\n",
    "original_states = dataset['State'].values\n",
    "encoded_df.insert(0, 'Original_State', original_states)\n",
    "\n",
    "print(f\"\\nüìä First 10 startups with encoding:\")\n",
    "display(encoded_df.head(10))\n",
    "\n",
    "print(f\"\\nüí° How to read this:\")\n",
    "print(f\"   üìç State_0, State_1, State_2: One-hot encoded state (1=Yes, 0=No)\")\n",
    "print(f\"   üí° R&D_Spend: Research & Development investment\")\n",
    "print(f\"   üíº Administration: Administrative costs\") \n",
    "print(f\"   üì± Marketing_Spend: Marketing investment\")\n",
    "\n",
    "# Show which state corresponds to which encoding\n",
    "print(f\"\\nüó∫Ô∏è State Encoding Reference:\")\n",
    "state_mapping = {}\n",
    "for i, state in enumerate(dataset['State'].unique()):\n",
    "    state_examples = dataset[dataset['State'] == state].index[:1]\n",
    "    for idx in state_examples:\n",
    "        encoding = X[idx][:3]  # First 3 columns are state encoding\n",
    "        state_col = np.where(encoding == 1)[0][0]\n",
    "        state_mapping[f'State_{state_col}'] = state\n",
    "        break\n",
    "\n",
    "for encoding, state in state_mapping.items():\n",
    "    print(f\"   {encoding} = {state}\")\n",
    "\n",
    "print(f\"\\n‚úÖ All features are now ready for Multiple Linear Regression!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba33f79e",
   "metadata": {},
   "source": [
    "## ‚úÇÔ∏è Step 5: Split Training and Test Sets\n",
    "\n",
    "**Why splitting is crucial for Multiple Linear Regression:**\n",
    "- **More features = higher risk of overfitting** (memorizing training data)\n",
    "- **Need to test generalization** across multiple dimensions\n",
    "- **Validation becomes more important** with complex models\n",
    "\n",
    "**Considerations for Multiple Features:**\n",
    "- **Stratification**: Ensure similar distributions across features\n",
    "- **Random state**: Reproducible splits for consistent results\n",
    "- **Sample size**: Need enough data for reliable training with multiple features\n",
    "\n",
    "**Our approach:**\n",
    "- **80/20 split**: 80% training (40 startups), 20% testing (10 startups)\n",
    "- **Random sampling**: Ensures representative distribution\n",
    "- **No data leakage**: Strict separation between train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4ca85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÇÔ∏è Splitting the dataset into Training and Test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(\"‚úÇÔ∏è DATA SPLITTING FOR MULTIPLE LINEAR REGRESSION\")\n",
    "print(\"=\"*55)\n",
    "\n",
    "# Split the data: 80% training, 20% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2,      # 20% for testing\n",
    "    random_state=42     # For reproducible results\n",
    ")\n",
    "\n",
    "print(f\"üìä SPLIT SUMMARY:\")\n",
    "print(f\"   üìã Original dataset: {len(dataset)} startups\")\n",
    "print(f\"   üéì Training set: {len(X_train)} startups ({len(X_train)/len(dataset)*100:.0f}%)\")\n",
    "print(f\"   üß™ Test set: {len(X_test)} startups ({len(X_test)/len(dataset)*100:.0f}%)\")\n",
    "\n",
    "print(f\"\\nüìè FEATURE DIMENSIONS:\")\n",
    "print(f\"   üéì Training features (X_train): {X_train.shape}\")\n",
    "print(f\"   üéØ Training target (y_train): {y_train.shape}\")\n",
    "print(f\"   üß™ Test features (X_test): {X_test.shape}\")\n",
    "print(f\"   üéØ Test target (y_test): {y_test.shape}\")\n",
    "\n",
    "print(f\"\\nüí° WHAT THIS MEANS:\")\n",
    "print(f\"   üìö Model will learn from {len(X_train)} startups with {X_train.shape[1]} features each\")\n",
    "print(f\"   üß™ Model will be tested on {len(X_test)} completely unseen startups\") \n",
    "print(f\"   üéØ Success = accurately predicting profits for test startups\")\n",
    "\n",
    "# Show some statistics about the split\n",
    "print(f\"\\nüìä PROFIT DISTRIBUTION COMPARISON:\")\n",
    "print(f\"   üí∞ Training set profit: ${y_train.mean():,.2f} ¬± ${y_train.std():,.2f}\")\n",
    "print(f\"   üí∞ Test set profit: ${y_test.mean():,.2f} ¬± ${y_test.std():,.2f}\")\n",
    "print(f\"   üìä Distribution similarity: {'‚úÖ Good' if abs(y_train.mean() - y_test.mean()) < y.std()*0.5 else '‚ö†Ô∏è Check'}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Data successfully split and ready for model training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238465db",
   "metadata": {},
   "source": [
    "## üéì Step 6: Train the Multiple Linear Regression Model\n",
    "\n",
    "**What happens during Multiple Linear Regression training?**\n",
    "\n",
    "**The Math (Don't worry, the computer handles this!):**\n",
    "```\n",
    "Profit = Œ≤‚ÇÄ + Œ≤‚ÇÅ√ó(State_0) + Œ≤‚ÇÇ√ó(State_1) + Œ≤‚ÇÉ√ó(State_2) + Œ≤‚ÇÑ√ó(R&D) + Œ≤‚ÇÖ√ó(Admin) + Œ≤‚ÇÜ√ó(Marketing)\n",
    "```\n",
    "\n",
    "**Where:**\n",
    "- **Œ≤‚ÇÄ** = Intercept (baseline profit)\n",
    "- **Œ≤‚ÇÅ, Œ≤‚ÇÇ, Œ≤‚ÇÉ** = Coefficients for state dummy variables  \n",
    "- **Œ≤‚ÇÑ** = How much profit changes per dollar of R&D spending\n",
    "- **Œ≤‚ÇÖ** = How much profit changes per dollar of admin spending\n",
    "- **Œ≤‚ÇÜ** = How much profit changes per dollar of marketing spending\n",
    "\n",
    "**The Learning Process:**\n",
    "1. **Start with random coefficients** for each feature\n",
    "2. **Calculate predictions** using current coefficients\n",
    "3. **Measure total error** (difference between predicted and actual profits)\n",
    "4. **Adjust coefficients** to minimize error\n",
    "5. **Repeat** until finding the best possible coefficients\n",
    "\n",
    "**Key Insight:** The model finds the optimal combination of all features simultaneously!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc422201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"‚ñ∏\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"‚ñæ\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LinearRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('fit_intercept',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">fit_intercept&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('copy_X',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">copy_X&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tol&nbsp;</td>\n",
       "            <td class=\"value\">1e-06</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('positive',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">positive&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# üéì Training the Multiple Linear Regression Model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "print(\"üéì MULTIPLE LINEAR REGRESSION TRAINING\")\n",
    "print(\"=\"*45)\n",
    "\n",
    "# Create the Multiple Linear Regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "print(\"üîß Model initialized - ready for training!\")\n",
    "print(f\"üìö Training on {len(X_train)} startups with {X_train.shape[1]} features each...\")\n",
    "\n",
    "# Fit the model to training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"‚úÖ Model training complete!\")\n",
    "\n",
    "# Extract the learned parameters\n",
    "coefficients = model.coef_\n",
    "intercept = model.intercept_\n",
    "\n",
    "print(f\"\\nüßÆ MODEL LEARNED PARAMETERS:\")\n",
    "print(f\"   üìç Intercept (Œ≤‚ÇÄ): ${intercept:,.2f}\")\n",
    "\n",
    "# Create feature names for better interpretation\n",
    "feature_names = ['State_0', 'State_1', 'State_2', 'R&D_Spend', 'Administration', 'Marketing_Spend']\n",
    "\n",
    "print(f\"\\nüìä FEATURE COEFFICIENTS:\")\n",
    "for i, (coef, feature) in enumerate(zip(coefficients, feature_names)):\n",
    "    if 'State' in feature:\n",
    "        print(f\"   üìç {feature}: ${coef:,.2f} (State effect)\")\n",
    "    else:\n",
    "        print(f\"   üí∞ {feature}: ${coef:.4f} (${coef:.4f} profit per $1 spent)\")\n",
    "\n",
    "print(f\"\\nüìù COMPLETE EQUATION:\")\n",
    "equation_parts = [f\"{intercept:,.2f}\"]\n",
    "for coef, feature in zip(coefficients, feature_names):\n",
    "    if coef >= 0:\n",
    "        equation_parts.append(f\"+ {coef:.4f}√ó{feature}\")\n",
    "    else:\n",
    "        equation_parts.append(f\"- {abs(coef):.4f}√ó{feature}\")\n",
    "\n",
    "equation = \"Profit = \" + \" \".join(equation_parts)\n",
    "print(f\"   {equation}\")\n",
    "\n",
    "# Training performance\n",
    "train_score = model.score(X_train, y_train)\n",
    "print(f\"\\nüìä TRAINING PERFORMANCE:\")\n",
    "print(f\"   üéØ R¬≤ Score: {train_score:.4f} ({train_score*100:.1f}% of variance explained)\")\n",
    "\n",
    "# Identify most important features\n",
    "abs_coefs = [(abs(coef), feature) for coef, feature in zip(coefficients, feature_names)]\n",
    "abs_coefs.sort(reverse=True)\n",
    "\n",
    "print(f\"\\nüèÜ FEATURE IMPORTANCE (by coefficient magnitude):\")\n",
    "for i, (abs_coef, feature) in enumerate(abs_coefs[:3]):\n",
    "    print(f\"   {i+1}. {feature}: {abs_coef:.4f}\")\n",
    "\n",
    "print(f\"\\nüéâ Multiple Linear Regression model is trained and ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ba5d53",
   "metadata": {},
   "source": [
    "## ‚öñÔ∏è Step 7: Feature Scaling - Do We Need It?\n",
    "\n",
    "**Feature Scaling in Multiple Linear Regression:**\n",
    "\n",
    "**Our current features have very different scales:**\n",
    "- **R&D Spend**: $0 - $200,000+\n",
    "- **Administration**: $0 - $200,000+  \n",
    "- **Marketing Spend**: $0 - $500,000+\n",
    "- **State variables**: 0 or 1\n",
    "\n",
    "**Does Multiple Linear Regression need feature scaling?**\n",
    "**Answer: NO!** ‚ùå\n",
    "\n",
    "**Why Linear Regression doesn't need scaling:**\n",
    "- **Scale-invariant coefficients**: The algorithm automatically adjusts coefficients based on feature scales\n",
    "- **Optimal solution unchanged**: Scaling doesn't change the fundamental relationships\n",
    "- **Interpretation**: Coefficients represent real-world units (profit per dollar spent)\n",
    "\n",
    "**When you WOULD need scaling:**\n",
    "- **Regularized regression** (Ridge, Lasso) - penalties depend on coefficient magnitudes\n",
    "- **Gradient descent optimization** - helps convergence speed\n",
    "- **Distance-based algorithms** (KNN, K-Means, SVM)\n",
    "- **Neural networks** - critical for proper learning\n",
    "\n",
    "**Our decision:** Skip scaling to maintain interpretable coefficients!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b384e3e",
   "metadata": {},
   "source": [
    "## üîÆ Step 8: Predict Test Set Results\n",
    "\n",
    "**The Ultimate Test for Multiple Linear Regression:**\n",
    "Now we'll see how well our model performs on 10 startups it has never seen before!\n",
    "\n",
    "**What happens:**\n",
    "1. **Input**: Test startups' R&D, Admin, Marketing spend, and State\n",
    "2. **Process**: Model applies learned equation with all 6 coefficients\n",
    "3. **Output**: Predicted profit for each test startup\n",
    "4. **Evaluation**: Compare predictions to actual profits\n",
    "\n",
    "**Key Questions:**\n",
    "- How accurate are our multi-feature predictions?\n",
    "- Which startups did we predict well/poorly?\n",
    "- Did using multiple features improve accuracy vs. single feature models?\n",
    "\n",
    "**Success Criteria:**\n",
    "- Predictions close to actual profits\n",
    "- No obvious systematic errors\n",
    "- Model generalizes well to new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98234cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîÆ Making Predictions on Test Set\n",
    "print(\"üîÆ MULTIPLE LINEAR REGRESSION PREDICTIONS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(f\"‚úÖ Predictions complete!\")\n",
    "print(f\"üìä Made predictions for {len(X_test)} test startups\")\n",
    "\n",
    "# Comprehensive evaluation metrics\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)  \n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"\\nüìè MODEL PERFORMANCE METRICS:\")\n",
    "print(f\"   üìä Mean Absolute Error (MAE): ${mae:,.2f}\")\n",
    "print(f\"   üìä Root Mean Squared Error (RMSE): ${rmse:,.2f}\")\n",
    "print(f\"   üìä R-squared (R¬≤): {r2:.4f}\")\n",
    "\n",
    "print(f\"\\nüí° WHAT THESE METRICS MEAN:\")\n",
    "print(f\"   üìä MAE: On average, predictions are off by ${mae:,.0f}\")\n",
    "print(f\"   üìä RMSE: Typical prediction error is ${rmse:,.0f} (penalizes large errors)\")\n",
    "print(f\"   üìä R¬≤: Model explains {r2*100:.1f}% of profit variation\")\n",
    "\n",
    "# Performance interpretation\n",
    "if r2 > 0.9:\n",
    "    performance = \"Excellent! üåü\"\n",
    "elif r2 > 0.8:\n",
    "    performance = \"Very Good! üëç\"\n",
    "elif r2 > 0.7:\n",
    "    performance = \"Good! üëå\"\n",
    "elif r2 > 0.5:\n",
    "    performance = \"Moderate üìà\"\n",
    "else:\n",
    "    performance = \"Needs Improvement üìä\"\n",
    "\n",
    "print(f\"   üìà Overall Performance: {performance}\")\n",
    "\n",
    "print(f\"\\nüîç DETAILED PREDICTIONS vs ACTUAL:\")\n",
    "print(f\"{'Startup':<8} {'Actual Profit':<15} {'Predicted':<15} {'Error':<12} {'% Error':<10}\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    actual = y_test.iloc[i]\n",
    "    predicted = y_pred[i]\n",
    "    error = abs(actual - predicted)\n",
    "    pct_error = (error / actual) * 100\n",
    "    \n",
    "    print(f\"Test {i+1:<3} ${actual:<14,.0f} ${predicted:<14,.0f} ${error:<11,.0f} {pct_error:<9.1f}%\")\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"\\nüìä ERROR ANALYSIS:\")\n",
    "errors = np.abs(y_test.values - y_pred)\n",
    "print(f\"   üéØ Best prediction error: ${errors.min():,.0f}\")\n",
    "print(f\"   üìä Worst prediction error: ${errors.max():,.0f}\")\n",
    "print(f\"   üìà Average percentage error: {np.mean(np.abs(y_test.values - y_pred) / y_test.values * 100):.1f}%\")\n",
    "\n",
    "print(f\"\\n‚úÖ Test set evaluation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f32d9ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[103015.20159796 132582.27760815 132447.73845174  71976.09851258\n",
      " 178537.48221056 116161.24230167  67851.69209676  98791.73374687\n",
      " 113969.43533014 167921.06569551]\n"
     ]
    }
   ],
   "source": [
    "# üìä Comprehensive Results Analysis and Visualization\n",
    "print(\"üìä COMPREHENSIVE RESULTS ANALYSIS\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# Create detailed results DataFrame\n",
    "results_df = pd.DataFrame({\n",
    "    'Startup_ID': [f'Test_{i+1}' for i in range(len(X_test))],\n",
    "    'Actual_Profit': y_test.values,\n",
    "    'Predicted_Profit': y_pred,\n",
    "    'Absolute_Error': np.abs(y_test.values - y_pred),\n",
    "    'Percentage_Error': np.abs(y_test.values - y_pred) / y_test.values * 100,\n",
    "    'R&D_Spend': X_test[:, 3],  # R&D is 4th column after one-hot encoding\n",
    "    'Administration': X_test[:, 4],  # Admin is 5th column\n",
    "    'Marketing_Spend': X_test[:, 5]  # Marketing is 6th column\n",
    "})\n",
    "\n",
    "print(f\"üìã COMPLETE RESULTS TABLE:\")\n",
    "display(results_df.round(2))\n",
    "\n",
    "# Visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# 1. Actual vs Predicted scatter plot\n",
    "axes[0,0].scatter(y_test, y_pred, color='blue', alpha=0.7, s=100)\n",
    "axes[0,0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', linewidth=2)\n",
    "axes[0,0].set_xlabel('Actual Profit ($)')\n",
    "axes[0,0].set_ylabel('Predicted Profit ($)')\n",
    "axes[0,0].set_title('üéØ Actual vs Predicted Profits')\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Add R¬≤ to the plot\n",
    "axes[0,0].text(0.05, 0.95, f'R¬≤ = {r2:.3f}', transform=axes[0,0].transAxes,\n",
    "               bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightblue\"),\n",
    "               verticalalignment='top')\n",
    "\n",
    "# 2. Residuals plot\n",
    "residuals = y_test.values - y_pred\n",
    "axes[0,1].scatter(y_pred, residuals, color='green', alpha=0.7, s=100)\n",
    "axes[0,1].axhline(0, color='red', linestyle='--', alpha=0.8)\n",
    "axes[0,1].set_xlabel('Predicted Profit ($)')\n",
    "axes[0,1].set_ylabel('Residuals ($)')\n",
    "axes[0,1].set_title('üîç Residuals vs Predicted')\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Feature importance visualization\n",
    "feature_names = ['State_0', 'State_1', 'State_2', 'R&D_Spend', 'Administration', 'Marketing_Spend']\n",
    "abs_coefs = np.abs(coefficients)\n",
    "colors = ['lightcoral' if 'State' in name else 'skyblue' for name in feature_names]\n",
    "\n",
    "axes[1,0].bar(range(len(feature_names)), abs_coefs, color=colors, alpha=0.7)\n",
    "axes[1,0].set_xlabel('Features')\n",
    "axes[1,0].set_ylabel('Absolute Coefficient Value')\n",
    "axes[1,0].set_title('üìä Feature Importance (Coefficient Magnitude)')\n",
    "axes[1,0].set_xticks(range(len(feature_names)))\n",
    "axes[1,0].set_xticklabels(feature_names, rotation=45, ha='right')\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Error distribution\n",
    "axes[1,1].hist(results_df['Absolute_Error'], bins=8, color='orange', alpha=0.7, edgecolor='black')\n",
    "axes[1,1].set_xlabel('Absolute Error ($)')\n",
    "axes[1,1].set_ylabel('Frequency')\n",
    "axes[1,1].set_title('üìà Distribution of Prediction Errors')\n",
    "axes[1,1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüí° KEY INSIGHTS:\")\n",
    "best_prediction = results_df.loc[results_df['Absolute_Error'].idxmin()]\n",
    "worst_prediction = results_df.loc[results_df['Absolute_Error'].idxmax()]\n",
    "\n",
    "print(f\"   üèÜ Best Prediction: {best_prediction['Startup_ID']} (Error: ${best_prediction['Absolute_Error']:,.0f})\")\n",
    "print(f\"   üìä Worst Prediction: {worst_prediction['Startup_ID']} (Error: ${worst_prediction['Absolute_Error']:,.0f})\")\n",
    "\n",
    "# Feature insights based on coefficients\n",
    "most_important_feature = feature_names[np.argmax(abs_coefs)]\n",
    "print(f\"   üéØ Most Important Feature: {most_important_feature}\")\n",
    "\n",
    "print(f\"\\nüéâ Multiple Linear Regression analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ceaa52",
   "metadata": {},
   "source": [
    "## üíº Business Insights and Practical Applications\n",
    "\n",
    "**üèÜ What Our Model Learned About Startup Success:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9af73bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üíº Business Insights from Multiple Linear Regression\n",
    "print(\"üíº BUSINESS INSIGHTS & APPLICATIONS\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# Analyze coefficient meanings in business context\n",
    "print(\"üßÆ COEFFICIENT INTERPRETATION:\")\n",
    "feature_names = ['State_0', 'State_1', 'State_2', 'R&D_Spend', 'Administration', 'Marketing_Spend']\n",
    "\n",
    "for coef, feature in zip(coefficients, feature_names):\n",
    "    if 'State' in feature:\n",
    "        state_effect = \"positive\" if coef > 0 else \"negative\"\n",
    "        print(f\"   üìç {feature}: ${coef:,.0f} ({state_effect} location effect)\")\n",
    "    else:\n",
    "        roi = coef * 100  # Return on $100 investment\n",
    "        if coef > 0:\n",
    "            print(f\"   üí∞ {feature}: ${coef:.4f} profit per $1 ‚Üí ${roi:.2f} profit per $100 invested\")\n",
    "        else:\n",
    "            print(f\"   ‚ö†Ô∏è {feature}: ${coef:.4f} profit per $1 ‚Üí NEGATIVE return of ${abs(roi):.2f} per $100\")\n",
    "\n",
    "print(f\"\\nüéØ KEY BUSINESS FINDINGS:\")\n",
    "\n",
    "# Find most profitable investment\n",
    "business_features = ['R&D_Spend', 'Administration', 'Marketing_Spend']  \n",
    "business_coefs = coefficients[3:6]  # Skip state dummy variables\n",
    "business_names = feature_names[3:6]\n",
    "\n",
    "best_investment_idx = np.argmax(business_coefs)\n",
    "worst_investment_idx = np.argmin(business_coefs)\n",
    "\n",
    "best_feature = business_names[best_investment_idx]\n",
    "best_roi = business_coefs[best_investment_idx]\n",
    "worst_feature = business_names[worst_investment_idx]  \n",
    "worst_roi = business_coefs[worst_investment_idx]\n",
    "\n",
    "print(f\"   üèÜ Best Investment: {best_feature}\")\n",
    "print(f\"      üí∞ ROI: ${best_roi:.4f} profit per $1 spent\")\n",
    "print(f\"      üìà Strategy: Increase {best_feature.replace('_', ' ')} for maximum profit\")\n",
    "\n",
    "print(f\"   üìâ Least Effective: {worst_feature}\")\n",
    "print(f\"      üí∏ ROI: ${worst_roi:.4f} profit per $1 spent\")\n",
    "if worst_roi < 0:\n",
    "    print(f\"      ‚ö†Ô∏è Warning: This actually REDUCES profit!\")\n",
    "else:\n",
    "    print(f\"      üìä Still positive but less efficient\")\n",
    "\n",
    "# Portfolio recommendations\n",
    "print(f\"\\nüí° INVESTMENT RECOMMENDATIONS:\")\n",
    "print(f\"   üéØ For New Startups:\")\n",
    "print(f\"      1. Prioritize {best_feature.replace('_', ' ')} (highest ROI)\")\n",
    "print(f\"      2. Optimize {worst_feature.replace('_', ' ')} spending\")\n",
    "print(f\"      3. Consider location effects in planning\")\n",
    "\n",
    "print(f\"   üìä For Investors:\")\n",
    "print(f\"      ‚Ä¢ Look for startups with high {best_feature.replace('_', ' ')}\")\n",
    "print(f\"      ‚Ä¢ Question high {worst_feature.replace('_', ' ')} without results\")\n",
    "print(f\"      ‚Ä¢ Consider geographic factors in valuation\")\n",
    "\n",
    "# Prediction confidence\n",
    "prediction_accuracy = (1 - mae/y_test.mean()) * 100\n",
    "print(f\"\\nüéØ MODEL RELIABILITY:\")\n",
    "print(f\"   üìä Prediction Accuracy: {prediction_accuracy:.1f}%\")\n",
    "print(f\"   üìè Typical Error: ${mae:,.0f} (¬±{mae/y_test.mean()*100:.1f}% of average profit)\")\n",
    "print(f\"   ‚úÖ Confidence Level: {'High' if prediction_accuracy > 80 else 'Moderate' if prediction_accuracy > 70 else 'Low'}\")\n",
    "\n",
    "print(f\"\\nüöÄ PRACTICAL APPLICATIONS:\")\n",
    "print(f\"   üíº Startup Founders: Optimize spending allocation\")\n",
    "print(f\"   üèõÔ∏è Investors: Screen and value startups\")\n",
    "print(f\"   üìä Business Analysts: Benchmark performance\")\n",
    "print(f\"   üéØ Strategic Planning: Resource allocation decisions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9baf903d",
   "metadata": {},
   "source": [
    "## üéâ Summary and Key Takeaways\n",
    "\n",
    "**üèÜ What We Accomplished:**\n",
    "1. ‚úÖ **Mastered Multiple Linear Regression** - Using multiple features simultaneously\n",
    "2. ‚úÖ **Learned categorical encoding** - Converting text to numbers (one-hot encoding)\n",
    "3. ‚úÖ **Built a business prediction model** - Startup profit forecasting\n",
    "4. ‚úÖ **Interpreted complex coefficients** - Understanding feature importance\n",
    "5. ‚úÖ **Applied to real business decisions** - Investment and strategy recommendations\n",
    "\n",
    "**üìä Our Model's Performance:**\n",
    "- **R¬≤ Score**: {r2:.3f} (explains {r2*100:.1f}% of profit variation)\n",
    "- **Average Error**: ${mae:,.0f}\n",
    "- **Business Impact**: Clear ROI insights for different spending categories\n",
    "\n",
    "**üí° Key Differences from Simple Linear Regression:**\n",
    "- **Multiple features**: 6 features instead of 1\n",
    "- **Categorical encoding**: Converted state names to numbers\n",
    "- **Complex relationships**: Multiple factors affecting the outcome simultaneously\n",
    "- **Higher complexity**: More coefficients to interpret\n",
    "- **Better predictions**: Usually more accurate than single-feature models\n",
    "\n",
    "**üß† Machine Learning Concepts Mastered:**\n",
    "- **Feature Engineering**: Preparing categorical variables for modeling\n",
    "- **Multiple Linear Regression**: The math and intuition behind multi-feature models\n",
    "- **Coefficient Interpretation**: Understanding what each number means in business terms\n",
    "- **Model Complexity**: Balancing accuracy with interpretability\n",
    "- **Business Application**: Translating technical results into actionable insights\n",
    "\n",
    "**üéØ When to Use Multiple Linear Regression:**\n",
    "- ‚úÖ **Multiple numerical features** available\n",
    "- ‚úÖ **Linear relationships** between features and target\n",
    "- ‚úÖ **Need interpretable results** (coefficients have clear meaning)\n",
    "- ‚úÖ **Baseline model** before trying complex algorithms\n",
    "- ‚úÖ **Business context** where feature importance matters\n",
    "\n",
    "**‚ö†Ô∏è Limitations to Remember:**\n",
    "- **Assumes linear relationships** (reality is often non-linear)\n",
    "- **Sensitive to outliers** (extreme values can skew results)\n",
    "- **Multicollinearity issues** (when features are highly correlated)\n",
    "- **No automatic feature selection** (includes all provided features)\n",
    "\n",
    "**üöÄ Next Steps in Your ML Journey:**\n",
    "1. **Try Polynomial Regression** - Handle non-linear relationships\n",
    "2. **Learn Regularization** - Ridge and Lasso regression for feature selection\n",
    "3. **Explore Tree-Based Models** - Decision trees and random forests\n",
    "4. **Master Cross-Validation** - More robust model evaluation\n",
    "5. **Feature Selection Techniques** - Automatically choose the best features\n",
    "\n",
    "**üíº Real-World Applications:**\n",
    "- **Sales Forecasting**: Multiple factors affecting revenue\n",
    "- **Real Estate Pricing**: Location, size, amenities, etc.\n",
    "- **Medical Diagnosis**: Multiple symptoms predicting conditions  \n",
    "- **Marketing ROI**: Different channels contributing to conversions\n",
    "- **Supply Chain Optimization**: Multiple costs affecting total expenses\n",
    "\n",
    "---\n",
    "\n",
    "**Congratulations! üéâ You've successfully built and interpreted a Multiple Linear Regression model that can guide real business decisions!**\n",
    "\n",
    "**üîë Remember**: The power of Multiple Linear Regression lies not just in making predictions, but in understanding HOW different factors contribute to the outcome. This interpretability makes it invaluable for business strategy and decision-making!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
